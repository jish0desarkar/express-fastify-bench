# ðŸš€ Express vs Fastify Benchmark Suite

This repository ships identical Express 5 and Fastify 5 servers that serve a hefty JSON payload plus a shared `autocannon` harness so you can capture reproducible latency/throughput numbers. There is no database dependencyâ€”the goal is to isolate framework overhead, serialization costs, and schema validation.

---

## Stack at a Glance

- **Runtime & tooling** â€“ Node.js 20+, TypeScript, `pnpm@10.18.2`, `tsx` for dev/watch and `tsc` for builds.
- **Web frameworks** â€“ `express@5` (`src/express`) and `fastify@5` (`src/fastify`) exposing matching routes.
- **Payload** â€“ A single `mockResponse` object (`src/common/mock-response.ts`) that mimics a real-world systems report.
- **Benchmarking** â€“ Shared utilities (`src/common/bench-utils.ts`) plus entry points for Express and Fastify that save `.json` + `.txt` artifacts under `benchmarks/`.

---

## API Surface

| Server  | Port | Route                            | Description                                                                          |
| ------- | ---- | -------------------------------- | ------------------------------------------------------------------------------------ |
| Express | 3000 | `GET /mock-response`             | Returns `{ mockResponse }` with the large JSON payload.                              |
| Fastify | 3001 | `GET /mock-response-no-schema`   | Mirrors the Express route (no validation).                                           |
| Fastify | 3001 | `GET /mock-response-with-schema` | Responds with the payload itself (HTTP 201) and enforces the documented JSON schema. |

Use these endpoints as-is or extend both frameworks in parallel to keep comparisons fair.

---

## Requirements

1. **Node.js 20 or newer** â€“ the project is ESM-only and uses modern APIs.
2. **pnpm 10.18.2** â€“ enforced via the `packageManager` field for reproducible installs.
3. **autocannon** â€“ already listed as a dependency; no global install needed.

No PostgreSQL/Prisma setup is requiredâ€”the entire benchmark operates on in-memory data.

---

## Setup

```bash
pnpm install
```

The TypeScript build output lands in `dist/` when you run:

```bash
pnpm build
```

Running `pnpm type-check` performs a no-emit type pass, and `pnpm dev:*` commands (see below) rely on `tsx` so no additional watch tooling is necessary.

---

## Running the Servers

1. **Start Express (port 3000)**
   ```bash
   pnpm dev:express
   ```
2. **Start Fastify (port 3001)**
   ```bash
   pnpm dev:fastify
   ```

Both commands hot-reload on TypeScript edits. For production-style runs use:

```bash
pnpm build
pnpm start:express   # or pnpm start:fastify
```

---

## Benchmarking Workflow

1. Keep the target server running (Express on `http://localhost:3000`, Fastify on `http://localhost:3001`).
2. Execute the matching benchmark runner:
   ```bash
   pnpm exec tsx src/bench/fastify-bench.ts
   pnpm exec tsx src/bench/express-bench.ts
   ```
3. Each run iterates through the configured concurrency list (default `[200]`) for `DURATION` seconds (default `10`). Raw `autocannon` results are written to `benchmarks/<framework>/*.json` alongside a formatted text report with headline metrics.

The filenames follow `bench_c<connections>_d<duration>_<timestamp>.{json,txt}`, making it easy to diff multiple experiments.

---

## Customising Runs

- **Target URL** â€“ Change `TARGET_URL` inside `src/bench/express-bench.ts` or `src/bench/fastify-bench.ts` to point at any route you want to stress.
- **Connection profile** â€“ Adjust the `CONNECTIONS` array to sweep through multiple concurrency levels (e.g. `[50, 100, 500]`).
- **Duration & workers** â€“ Tune `DURATION` and `WORKERS` constants to lengthen tests or match the number of CPU threads on your machine.
- **Output directories** â€“ Update `OUT_DIR` if you want to store artifacts elsewhere; directories are created automatically.

`runAll` in `src/common/bench-utils.ts` drives these runners, tracks `autocannon` progress, and emits both machine-readable JSON and a human-friendly summary generated by `generateTextReport`.

---

## Available Scripts

| Command                                     | Purpose                                               |
| ------------------------------------------- | ----------------------------------------------------- |
| `pnpm dev:express` / `pnpm dev:fastify`     | Run the TypeScript sources directly with live reload. |
| `pnpm build`                                | Transpile everything into `dist/`.                    |
| `pnpm start:express` / `pnpm start:fastify` | Serve the compiled output.                            |
| `pnpm type-check`                           | Run `tsc --noEmit` for CI-friendly validation.        |

Benchmarks are invoked via `pnpm exec tsx src/bench/<framework>-bench.ts`, as shown above.

---

## Mock Payload

`src/common/mock-response.ts` contains the shared payloadâ€”an intentionally chunky object made up of nested structures (runtime metrics, geo data, cache stats, etc.). Fastify validates it via JSON schema for the `/mock-response-with-schema` route, while the Express and Fastify no-schema routes simply serialize it as-is. Editing this file is the quickest way to experiment with heavier responses.

---

## Troubleshooting

- **Port already in use:** stop any existing listeners on 3000/3001 or change the ports in `src/express/index.ts` / `src/fastify/index.ts`.
- **Benchmark exits immediately:** verify the corresponding server is running and that `TARGET_URL` matches the route + status code you expect.
- **`autocannon` errors about limits:** lower the `CONNECTIONS` count or shorten the duration when running on constrained hardware.
- **Missing output files:** ensure `benchmarks/` is writable (it is created automatically on success).

---

## Extending the Benchmarks

- Add new routes to both frameworks (e.g. headers-only responses, JSON schema variants, streaming) and wire fresh runners that import `runAll`.
- Introduce CLI flags or environment variables inside the bench entry points to tweak connections/durations without editing source.
- Hook the suite into CI/CD to catch regressions by committing the generated reports or comparing summary stats.
